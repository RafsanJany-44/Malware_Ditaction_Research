{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8f1200c",
   "metadata": {},
   "source": [
    "## 2.2.4 Feature Selection Methods (Random Forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30049787",
   "metadata": {},
   "source": [
    "## Pearson Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "227c3c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns:  50\n",
      "Testing Accuracy:  0.8974358974358975\n",
      "Training Accuracy:  0.9507494646680942\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  100\n",
      "Testing Accuracy:  0.8888888888888888\n",
      "Training Accuracy:  0.9678800856531049\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  150\n",
      "Testing Accuracy:  0.9145299145299145\n",
      "Training Accuracy:  0.9764453961456103\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  200\n",
      "Testing Accuracy:  0.9017094017094017\n",
      "Training Accuracy:  0.9785867237687366\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  250\n",
      "Testing Accuracy:  0.8931623931623932\n",
      "Training Accuracy:  0.9828693790149893\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  300\n",
      "Testing Accuracy:  0.9017094017094017\n",
      "Training Accuracy:  0.9775160599571735\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  350\n",
      "Testing Accuracy:  0.9017094017094017\n",
      "Training Accuracy:  0.9721627408993576\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  400\n",
      "Testing Accuracy:  0.905982905982906\n",
      "Training Accuracy:  0.974304068522484\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  450\n",
      "Testing Accuracy:  0.9230769230769231\n",
      "Training Accuracy:  0.9775160599571735\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  500\n",
      "Testing Accuracy:  0.8974358974358975\n",
      "Training Accuracy:  0.9635974304068522\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  550\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.9764453961456103\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  600\n",
      "Testing Accuracy:  0.8888888888888888\n",
      "Training Accuracy:  0.9668094218415417\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  650\n",
      "Testing Accuracy:  0.9017094017094017\n",
      "Training Accuracy:  0.974304068522484\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  700\n",
      "Testing Accuracy:  0.905982905982906\n",
      "Training Accuracy:  0.9721627408993576\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  750\n",
      "Testing Accuracy:  0.8888888888888888\n",
      "Training Accuracy:  0.9678800856531049\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  800\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.9775160599571735\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  850\n",
      "Testing Accuracy:  0.905982905982906\n",
      "Training Accuracy:  0.9850107066381156\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  900\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.9721627408993576\n",
      "___________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def pearson_selection(X, y, num_of_feat):\n",
    "    fs = SelectKBest(score_func=f_regression, k=num_of_feat)\n",
    "    fit = fs.fit(X, y)\n",
    "\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "    featureScores.columns = ['Best_columns', 'Score_pearson']\n",
    "\n",
    "    lyst = featureScores.nlargest(num_of_feat, 'Score_pearson')\n",
    "\n",
    "    pearson_features = list(lyst['Best_columns'])\n",
    "    return pearson_features\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"permission-based_malware_2.csv\")\n",
    "target = \"CLASS\"\n",
    "\n",
    "X = df.loc[:, df.columns != target]\n",
    "X = X.loc[:, X.columns != \"NAME\"]\n",
    "y = df[target]\n",
    "\n",
    "# Iterate over different numbers of features\n",
    "for i in range(50, len(X.columns), 50):\n",
    "    print(\"Number of columns: \", i)\n",
    "    pearson_list = pearson_selection(X, y, i)\n",
    "\n",
    "    X_ = df.loc[:, pearson_list]\n",
    "    y_ = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=0)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=11, max_depth=26, random_state=0)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_test = rf.predict(X_test)\n",
    "    print(\"Testing Accuracy: \", accuracy_score(y_test, y_pred_test))\n",
    "    \n",
    "    y_pred_train = rf.predict(X_train)\n",
    "    print(\"Training Accuracy: \", accuracy_score(y_train, y_pred_train))\n",
    "    print(\"___________________________________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f225127e",
   "metadata": {},
   "source": [
    "## Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70c11f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns:  50\n",
      "Testing Accuracy:  0.8760683760683761\n",
      "Training Accuracy:  0.9293361884368309\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  100\n",
      "Testing Accuracy:  0.8803418803418803\n",
      "Training Accuracy:  0.9646680942184154\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  150\n",
      "Testing Accuracy:  0.8589743589743589\n",
      "Training Accuracy:  0.9635974304068522\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  200\n",
      "Testing Accuracy:  0.8974358974358975\n",
      "Training Accuracy:  0.9625267665952891\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  250\n",
      "Testing Accuracy:  0.8547008547008547\n",
      "Training Accuracy:  0.9593147751605996\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  300\n",
      "Testing Accuracy:  0.8846153846153846\n",
      "Training Accuracy:  0.9603854389721628\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  350\n",
      "Testing Accuracy:  0.8846153846153846\n",
      "Training Accuracy:  0.9635974304068522\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  400\n",
      "Testing Accuracy:  0.8675213675213675\n",
      "Training Accuracy:  0.9603854389721628\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  450\n",
      "Testing Accuracy:  0.8931623931623932\n",
      "Training Accuracy:  0.9721627408993576\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  500\n",
      "Testing Accuracy:  0.8974358974358975\n",
      "Training Accuracy:  0.9753747323340471\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  550\n",
      "Testing Accuracy:  0.8846153846153846\n",
      "Training Accuracy:  0.9721627408993576\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  600\n",
      "Testing Accuracy:  0.8888888888888888\n",
      "Training Accuracy:  0.9753747323340471\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  650\n",
      "Testing Accuracy:  0.8888888888888888\n",
      "Training Accuracy:  0.9582441113490364\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  700\n",
      "Testing Accuracy:  0.8632478632478633\n",
      "Training Accuracy:  0.9603854389721628\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  750\n",
      "Testing Accuracy:  0.8760683760683761\n",
      "Training Accuracy:  0.9796573875802997\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  800\n",
      "Testing Accuracy:  0.9145299145299145\n",
      "Training Accuracy:  0.9807280513918629\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  850\n",
      "Testing Accuracy:  0.8888888888888888\n",
      "Training Accuracy:  0.9753747323340471\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  900\n",
      "Testing Accuracy:  0.8931623931623932\n",
      "Training Accuracy:  0.9700214132762313\n",
      "___________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def mutual_info_selection(X, y, num_of_feat):\n",
    "    fs = SelectKBest(score_func=mutual_info_classif, k=num_of_feat)\n",
    "    fit = fs.fit(X, y)\n",
    "\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "    featureScores.columns = ['Best_columns', 'Score_mutual_info']\n",
    "\n",
    "    lyst = featureScores.nlargest(num_of_feat, 'Score_mutual_info')\n",
    "\n",
    "    mutual_info_features = list(lyst['Best_columns'])\n",
    "    return mutual_info_features\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"permission-based_malware_2.csv\")\n",
    "target = \"CLASS\"\n",
    "\n",
    "X = df.loc[:, df.columns != target]\n",
    "X = X.loc[:, X.columns != \"NAME\"]\n",
    "y = df[target]\n",
    "\n",
    "# Iterate over different numbers of features\n",
    "for i in range(50, len(X.columns), 50):\n",
    "    print(\"Number of columns: \", i)\n",
    "    mutual_info_list = mutual_info_selection(X, y, i)\n",
    "\n",
    "    X_ = df.loc[:, mutual_info_list]\n",
    "    y_ = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=0)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=11, max_depth=26, random_state=0)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_test = rf.predict(X_test)\n",
    "    print(\"Testing Accuracy: \", accuracy_score(y_test, y_pred_test))\n",
    "    \n",
    "    y_pred_train = rf.predict(X_train)\n",
    "    print(\"Training Accuracy: \", accuracy_score(y_train, y_pred_train))\n",
    "    print(\"___________________________________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61832e4c",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db6a8250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns:  50\n",
      "Testing Accuracy:  0.9017094017094017\n",
      "Training Accuracy:  0.9357601713062098\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  100\n",
      "Testing Accuracy:  0.8888888888888888\n",
      "Training Accuracy:  0.9635974304068522\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  150\n",
      "Testing Accuracy:  0.905982905982906\n",
      "Training Accuracy:  0.961456102783726\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  200\n",
      "Testing Accuracy:  0.8974358974358975\n",
      "Training Accuracy:  0.9689507494646681\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  250\n",
      "Testing Accuracy:  0.8760683760683761\n",
      "Training Accuracy:  0.9764453961456103\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  300\n",
      "Testing Accuracy:  0.8803418803418803\n",
      "Training Accuracy:  0.9807280513918629\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  350\n",
      "Testing Accuracy:  0.9145299145299145\n",
      "Training Accuracy:  0.9839400428265525\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  400\n",
      "Testing Accuracy:  0.9230769230769231\n",
      "Training Accuracy:  0.9828693790149893\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  450\n",
      "Testing Accuracy:  0.9017094017094017\n",
      "Training Accuracy:  0.9839400428265525\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  500\n",
      "Testing Accuracy:  0.9145299145299145\n",
      "Training Accuracy:  0.9807280513918629\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  550\n",
      "Testing Accuracy:  0.9017094017094017\n",
      "Training Accuracy:  0.9807280513918629\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  600\n",
      "Testing Accuracy:  0.905982905982906\n",
      "Training Accuracy:  0.9732334047109208\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  650\n",
      "Testing Accuracy:  0.9230769230769231\n",
      "Training Accuracy:  0.9753747323340471\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  700\n",
      "Testing Accuracy:  0.8931623931623932\n",
      "Training Accuracy:  0.9700214132762313\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  750\n",
      "Testing Accuracy:  0.8846153846153846\n",
      "Training Accuracy:  0.9732334047109208\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  800\n",
      "Testing Accuracy:  0.8931623931623932\n",
      "Training Accuracy:  0.9807280513918629\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  850\n",
      "Testing Accuracy:  0.9316239316239316\n",
      "Training Accuracy:  0.9860813704496788\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  900\n",
      "Testing Accuracy:  0.8888888888888888\n",
      "Training Accuracy:  0.9678800856531049\n",
      "___________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def rfe_selection(X, y, num_of_feat):\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    rfe = RFE(model, n_features_to_select=num_of_feat)\n",
    "    fit = rfe.fit(X, y)\n",
    "\n",
    "    feature_ranks = pd.DataFrame(fit.ranking_, index=X.columns, columns=['Rank'])\n",
    "    selected_features = feature_ranks[feature_ranks['Rank'] == 1].index.tolist()\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"permission-based_malware_2.csv\")\n",
    "target = \"CLASS\"\n",
    "\n",
    "X = df.loc[:, df.columns != target]\n",
    "X = X.loc[:, X.columns != \"NAME\"]\n",
    "y = df[target]\n",
    "\n",
    "# Iterate over different numbers of features\n",
    "for i in range(50, len(X.columns), 50):\n",
    "    print(\"Number of columns: \", i)\n",
    "    rfe_list = rfe_selection(X, y, i)\n",
    "\n",
    "    X_ = df.loc[:, rfe_list]\n",
    "    y_ = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=0)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=11, max_depth=26, random_state=0)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_test = rf.predict(X_test)\n",
    "    print(\"Testing Accuracy: \", accuracy_score(y_test, y_pred_test))\n",
    "    \n",
    "    y_pred_train = rf.predict(X_train)\n",
    "    print(\"Training Accuracy: \", accuracy_score(y_train, y_pred_train))\n",
    "    print(\"___________________________________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680fdf59",
   "metadata": {},
   "source": [
    "## ANOVA F-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f582b1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns:  50\n",
      "Testing Accuracy:  0.8760683760683761\n",
      "Training Accuracy:  0.9507494646680942\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  100\n",
      "Testing Accuracy:  0.8803418803418803\n",
      "Training Accuracy:  0.9678800856531049\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  150\n",
      "Testing Accuracy:  0.9017094017094017\n",
      "Training Accuracy:  0.9775160599571735\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  2   4   7   8   9  10  11  14  15  17  19  20  21  22  25  26  27  28\n",
      "  29  30  31  33  37  38  39  40  41  43  44  45  46  47  48  49  50  51\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  75  76  77  78  79  80  82  86  88  89  90  92  93  95  96\n",
      "  97 100 106 108 109 110 112 113 115 116 117 118 119 123 125 126 127 129\n",
      " 130 132 133 135 137 138 139 140 141 142 143 144 146 147 150 151 152 154\n",
      " 156 157 159 164 166 167 169 170 172 173 174 175 176 178 179 180 181 182\n",
      " 183 184 185 186 187 189 190 192 193 194 195 199 200 201 203 204 205 206\n",
      " 207 209 210 211 212 213 215 216 217 218 219 220 222 225 226 227 230 235\n",
      " 238 240 241 242 243 244 245 246 247 248 249 250 251 252 256 257 259 260\n",
      " 261 262 263 265 266 267 268 269 272 273 275 277 278 279 284 285 286 287\n",
      " 288 290 292 295 297 298 299 301 302 303 305 307 308 309 314 315 316] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  2   4   7   8   9  10  11  14  15  17  19  20  21  22  25  26  27  28\n",
      "  29  30  31  33  37  38  39  40  41  43  44  45  46  47  48  49  50  51\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  75  76  77  78  79  80  82  86  88  89  90  92  93  95  96\n",
      "  97 100 106 108 109 110 112 113 115 116 117 118 119 123 125 126 127 129\n",
      " 130 132 133 135 137 138 139 140 141 142 143 144 146 147 150 151 152 154\n",
      " 156 157 159 164 166 167 169 170 172 173 174 175 176 178 179 180 181 182\n",
      " 183 184 185 186 187 189 190 192 193 194 195 199 200 201 203 204 205 206\n",
      " 207 209 210 211 212 213 215 216 217 218 219 220 222 225 226 227 230 235\n",
      " 238 240 241 242 243 244 245 246 247 248 249 250 251 252 256 257 259 260\n",
      " 261 262 263 265 266 267 268 269 272 273 275 277 278 279 284 285 286 287\n",
      " 288 290 292 295 297 298 299 301 302 303 305 307 308 309 314 315 316] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  2   4   7   8   9  10  11  14  15  17  19  20  21  22  25  26  27  28\n",
      "  29  30  31  33  37  38  39  40  41  43  44  45  46  47  48  49  50  51\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  75  76  77  78  79  80  82  86  88  89  90  92  93  95  96\n",
      "  97 100 106 108 109 110 112 113 115 116 117 118 119 123 125 126 127 129\n",
      " 130 132 133 135 137 138 139 140 141 142 143 144 146 147 150 151 152 154\n",
      " 156 157 159 164 166 167 169 170 172 173 174 175 176 178 179 180 181 182\n",
      " 183 184 185 186 187 189 190 192 193 194 195 199 200 201 203 204 205 206\n",
      " 207 209 210 211 212 213 215 216 217 218 219 220 222 225 226 227 230 235\n",
      " 238 240 241 242 243 244 245 246 247 248 249 250 251 252 256 257 259 260\n",
      " 261 262 263 265 266 267 268 269 272 273 275 277 278 279 284 285 286 287\n",
      " 288 290 292 295 297 298 299 301 302 303 305 307 308 309 314 315 316] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.9017094017094017\n",
      "Training Accuracy:  0.9785867237687366\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  2   4   7   8   9  10  11  14  15  17  19  20  21  22  25  26  27  28\n",
      "  29  30  31  33  37  38  39  40  41  43  44  45  46  47  48  49  50  51\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  75  76  77  78  79  80  82  86  88  89  90  92  93  95  96\n",
      "  97 100 106 108 109 110 112 113 115 116 117 118 119 123 125 126 127 129\n",
      " 130 132 133 135 137 138 139 140 141 142 143 144 146 147 150 151 152 154\n",
      " 156 157 159 164 166 167 169 170 172 173 174 175 176 178 179 180 181 182\n",
      " 183 184 185 186 187 189 190 192 193 194 195 199 200 201 203 204 205 206\n",
      " 207 209 210 211 212 213 215 216 217 218 219 220 222 225 226 227 230 235\n",
      " 238 240 241 242 243 244 245 246 247 248 249 250 251 252 256 257 259 260\n",
      " 261 262 263 265 266 267 268 269 272 273 275 277 278 279 284 285 286 287\n",
      " 288 290 292 295 297 298 299 301 302 303 305 307 308 309 314 315 316] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  2   4   7   8   9  10  11  14  15  17  19  20  21  22  25  26  27  28\n",
      "  29  30  31  33  37  38  39  40  41  43  44  45  46  47  48  49  50  51\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  75  76  77  78  79  80  82  86  88  89  90  92  93  95  96\n",
      "  97 100 106 108 109 110 112 113 115 116 117 118 119 123 125 126 127 129\n",
      " 130 132 133 135 137 138 139 140 141 142 143 144 146 147 150 151 152 154\n",
      " 156 157 159 164 166 167 169 170 172 173 174 175 176 178 179 180 181 182\n",
      " 183 184 185 186 187 189 190 192 193 194 195 199 200 201 203 204 205 206\n",
      " 207 209 210 211 212 213 215 216 217 218 219 220 222 225 226 227 230 235\n",
      " 238 240 241 242 243 244 245 246 247 248 249 250 251 252 256 257 259 260\n",
      " 261 262 263 265 266 267 268 269 272 273 275 277 278 279 284 285 286 287\n",
      " 288 290 292 295 297 298 299 301 302 303 305 307 308 309 314 315 316] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  2   4   7   8   9  10  11  14  15  17  19  20  21  22  25  26  27  28\n",
      "  29  30  31  33  37  38  39  40  41  43  44  45  46  47  48  49  50  51\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  75  76  77  78  79  80  82  86  88  89  90  92  93  95  96\n",
      "  97 100 106 108 109 110 112 113 115 116 117 118 119 123 125 126 127 129\n",
      " 130 132 133 135 137 138 139 140 141 142 143 144 146 147 150 151 152 154\n",
      " 156 157 159 164 166 167 169 170 172 173 174 175 176 178 179 180 181 182\n",
      " 183 184 185 186 187 189 190 192 193 194 195 199 200 201 203 204 205 206\n",
      " 207 209 210 211 212 213 215 216 217 218 219 220 222 225 226 227 230 235\n",
      " 238 240 241 242 243 244 245 246 247 248 249 250 251 252 256 257 259 260\n",
      " 261 262 263 265 266 267 268 269 272 273 275 277 278 279 284 285 286 287\n",
      " 288 290 292 295 297 298 299 301 302 303 305 307 308 309 314 315 316] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.9145299145299145\n",
      "Training Accuracy:  0.9796573875802997\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  300\n",
      "Testing Accuracy:  0.905982905982906\n",
      "Training Accuracy:  0.9764453961456103\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  350\n",
      "Testing Accuracy:  0.8974358974358975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  2   4   7   8   9  10  11  14  15  17  19  20  21  22  25  26  27  28\n",
      "  29  30  31  33  37  38  39  40  41  43  44  45  46  47  48  49  50  51\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  75  76  77  78  79  80  82  86  88  89  90  92  93  95  96\n",
      "  97 100 106 108 109 110 112 113 115 116 117 118 119 123 125 126 127 129\n",
      " 130 132 133 135 137 138 139 140 141 142 143 144 146 147 150 151 152 154\n",
      " 156 157 159 164 166 167 169 170 172 173 174 175 176 178 179 180 181 182\n",
      " 183 184 185 186 187 189 190 192 193 194 195 199 200 201 203 204 205 206\n",
      " 207 209 210 211 212 213 215 216 217 218 219 220 222 225 226 227 230 235\n",
      " 238 240 241 242 243 244 245 246 247 248 249 250 251 252 256 257 259 260\n",
      " 261 262 263 265 266 267 268 269 272 273 275 277 278 279 284 285 286 287\n",
      " 288 290 292 295 297 298 299 301 302 303 305 307 308 309 314 315 316] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  2   4   7   8   9  10  11  14  15  17  19  20  21  22  25  26  27  28\n",
      "  29  30  31  33  37  38  39  40  41  43  44  45  46  47  48  49  50  51\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  75  76  77  78  79  80  82  86  88  89  90  92  93  95  96\n",
      "  97 100 106 108 109 110 112 113 115 116 117 118 119 123 125 126 127 129\n",
      " 130 132 133 135 137 138 139 140 141 142 143 144 146 147 150 151 152 154\n",
      " 156 157 159 164 166 167 169 170 172 173 174 175 176 178 179 180 181 182\n",
      " 183 184 185 186 187 189 190 192 193 194 195 199 200 201 203 204 205 206\n",
      " 207 209 210 211 212 213 215 216 217 218 219 220 222 225 226 227 230 235\n",
      " 238 240 241 242 243 244 245 246 247 248 249 250 251 252 256 257 259 260\n",
      " 261 262 263 265 266 267 268 269 272 273 275 277 278 279 284 285 286 287\n",
      " 288 290 292 295 297 298 299 301 302 303 305 307 308 309 314 315 316] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  2   4   7   8   9  10  11  14  15  17  19  20  21  22  25  26  27  28\n",
      "  29  30  31  33  37  38  39  40  41  43  44  45  46  47  48  49  50  51\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  75  76  77  78  79  80  82  86  88  89  90  92  93  95  96\n",
      "  97 100 106 108 109 110 112 113 115 116 117 118 119 123 125 126 127 129\n",
      " 130 132 133 135 137 138 139 140 141 142 143 144 146 147 150 151 152 154\n",
      " 156 157 159 164 166 167 169 170 172 173 174 175 176 178 179 180 181 182\n",
      " 183 184 185 186 187 189 190 192 193 194 195 199 200 201 203 204 205 206\n",
      " 207 209 210 211 212 213 215 216 217 218 219 220 222 225 226 227 230 235\n",
      " 238 240 241 242 243 244 245 246 247 248 249 250 251 252 256 257 259 260\n",
      " 261 262 263 265 266 267 268 269 272 273 275 277 278 279 284 285 286 287\n",
      " 288 290 292 295 297 298 299 301 302 303 305 307 308 309 314 315 316] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.9764453961456103\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  400\n",
      "Testing Accuracy:  0.9273504273504274\n",
      "Training Accuracy:  0.9721627408993576\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  450\n",
      "Testing Accuracy:  0.9145299145299145\n",
      "Training Accuracy:  0.9764453961456103\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  2   4   7   8   9  10  11  14  15  17  19  20  21  22  25  26  27  28\n",
      "  29  30  31  33  37  38  39  40  41  43  44  45  46  47  48  49  50  51\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  75  76  77  78  79  80  82  86  88  89  90  92  93  95  96\n",
      "  97 100 106 108 109 110 112 113 115 116 117 118 119 123 125 126 127 129\n",
      " 130 132 133 135 137 138 139 140 141 142 143 144 146 147 150 151 152 154\n",
      " 156 157 159 164 166 167 169 170 172 173 174 175 176 178 179 180 181 182\n",
      " 183 184 185 186 187 189 190 192 193 194 195 199 200 201 203 204 205 206\n",
      " 207 209 210 211 212 213 215 216 217 218 219 220 222 225 226 227 230 235\n",
      " 238 240 241 242 243 244 245 246 247 248 249 250 251 252 256 257 259 260\n",
      " 261 262 263 265 266 267 268 269 272 273 275 277 278 279 284 285 286 287\n",
      " 288 290 292 295 297 298 299 301 302 303 305 307 308 309 314 315 316] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  2   4   7   8   9  10  11  14  15  17  19  20  21  22  25  26  27  28\n",
      "  29  30  31  33  37  38  39  40  41  43  44  45  46  47  48  49  50  51\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  75  76  77  78  79  80  82  86  88  89  90  92  93  95  96\n",
      "  97 100 106 108 109 110 112 113 115 116 117 118 119 123 125 126 127 129\n",
      " 130 132 133 135 137 138 139 140 141 142 143 144 146 147 150 151 152 154\n",
      " 156 157 159 164 166 167 169 170 172 173 174 175 176 178 179 180 181 182\n",
      " 183 184 185 186 187 189 190 192 193 194 195 199 200 201 203 204 205 206\n",
      " 207 209 210 211 212 213 215 216 217 218 219 220 222 225 226 227 230 235\n",
      " 238 240 241 242 243 244 245 246 247 248 249 250 251 252 256 257 259 260\n",
      " 261 262 263 265 266 267 268 269 272 273 275 277 278 279 284 285 286 287\n",
      " 288 290 292 295 297 298 299 301 302 303 305 307 308 309 314 315 316] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  2   4   7   8   9  10  11  14  15  17  19  20  21  22  25  26  27  28\n",
      "  29  30  31  33  37  38  39  40  41  43  44  45  46  47  48  49  50  51\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  75  76  77  78  79  80  82  86  88  89  90  92  93  95  96\n",
      "  97 100 106 108 109 110 112 113 115 116 117 118 119 123 125 126 127 129\n",
      " 130 132 133 135 137 138 139 140 141 142 143 144 146 147 150 151 152 154\n",
      " 156 157 159 164 166 167 169 170 172 173 174 175 176 178 179 180 181 182\n",
      " 183 184 185 186 187 189 190 192 193 194 195 199 200 201 203 204 205 206\n",
      " 207 209 210 211 212 213 215 216 217 218 219 220 222 225 226 227 230 235\n",
      " 238 240 241 242 243 244 245 246 247 248 249 250 251 252 256 257 259 260\n",
      " 261 262 263 265 266 267 268 269 272 273 275 277 278 279 284 285 286 287\n",
      " 288 290 292 295 297 298 299 301 302 303 305 307 308 309 314 315 316] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.8974358974358975\n",
      "Training Accuracy:  0.9764453961456103\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  550\n",
      "Testing Accuracy:  0.9102564102564102\n",
      "Training Accuracy:  0.9753747323340471\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  600\n",
      "Testing Accuracy:  0.9230769230769231\n",
      "Training Accuracy:  0.9721627408993576\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  2   4   7   8   9  10  11  14  15  17  19  20  21  22  25  26  27  28\n",
      "  29  30  31  33  37  38  39  40  41  43  44  45  46  47  48  49  50  51\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  75  76  77  78  79  80  82  86  88  89  90  92  93  95  96\n",
      "  97 100 106 108 109 110 112 113 115 116 117 118 119 123 125 126 127 129\n",
      " 130 132 133 135 137 138 139 140 141 142 143 144 146 147 150 151 152 154\n",
      " 156 157 159 164 166 167 169 170 172 173 174 175 176 178 179 180 181 182\n",
      " 183 184 185 186 187 189 190 192 193 194 195 199 200 201 203 204 205 206\n",
      " 207 209 210 211 212 213 215 216 217 218 219 220 222 225 226 227 230 235\n",
      " 238 240 241 242 243 244 245 246 247 248 249 250 251 252 256 257 259 260\n",
      " 261 262 263 265 266 267 268 269 272 273 275 277 278 279 284 285 286 287\n",
      " 288 290 292 295 297 298 299 301 302 303 305 307 308 309 314 315 316] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  2   4   7   8   9  10  11  14  15  17  19  20  21  22  25  26  27  28\n",
      "  29  30  31  33  37  38  39  40  41  43  44  45  46  47  48  49  50  51\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  75  76  77  78  79  80  82  86  88  89  90  92  93  95  96\n",
      "  97 100 106 108 109 110 112 113 115 116 117 118 119 123 125 126 127 129\n",
      " 130 132 133 135 137 138 139 140 141 142 143 144 146 147 150 151 152 154\n",
      " 156 157 159 164 166 167 169 170 172 173 174 175 176 178 179 180 181 182\n",
      " 183 184 185 186 187 189 190 192 193 194 195 199 200 201 203 204 205 206\n",
      " 207 209 210 211 212 213 215 216 217 218 219 220 222 225 226 227 230 235\n",
      " 238 240 241 242 243 244 245 246 247 248 249 250 251 252 256 257 259 260\n",
      " 261 262 263 265 266 267 268 269 272 273 275 277 278 279 284 285 286 287\n",
      " 288 290 292 295 297 298 299 301 302 303 305 307 308 309 314 315 316] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  2   4   7   8   9  10  11  14  15  17  19  20  21  22  25  26  27  28\n",
      "  29  30  31  33  37  38  39  40  41  43  44  45  46  47  48  49  50  51\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  75  76  77  78  79  80  82  86  88  89  90  92  93  95  96\n",
      "  97 100 106 108 109 110 112 113 115 116 117 118 119 123 125 126 127 129\n",
      " 130 132 133 135 137 138 139 140 141 142 143 144 146 147 150 151 152 154\n",
      " 156 157 159 164 166 167 169 170 172 173 174 175 176 178 179 180 181 182\n",
      " 183 184 185 186 187 189 190 192 193 194 195 199 200 201 203 204 205 206\n",
      " 207 209 210 211 212 213 215 216 217 218 219 220 222 225 226 227 230 235\n",
      " 238 240 241 242 243 244 245 246 247 248 249 250 251 252 256 257 259 260\n",
      " 261 262 263 265 266 267 268 269 272 273 275 277 278 279 284 285 286 287\n",
      " 288 290 292 295 297 298 299 301 302 303 305 307 308 309 314 315 316] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.9145299145299145\n",
      "Training Accuracy:  0.9753747323340471\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  700\n",
      "Testing Accuracy:  0.9102564102564102\n",
      "Training Accuracy:  0.974304068522484\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  750\n",
      "Testing Accuracy:  0.905982905982906\n",
      "Training Accuracy:  0.974304068522484\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  2   4   7   8   9  10  11  14  15  17  19  20  21  22  25  26  27  28\n",
      "  29  30  31  33  37  38  39  40  41  43  44  45  46  47  48  49  50  51\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  75  76  77  78  79  80  82  86  88  89  90  92  93  95  96\n",
      "  97 100 106 108 109 110 112 113 115 116 117 118 119 123 125 126 127 129\n",
      " 130 132 133 135 137 138 139 140 141 142 143 144 146 147 150 151 152 154\n",
      " 156 157 159 164 166 167 169 170 172 173 174 175 176 178 179 180 181 182\n",
      " 183 184 185 186 187 189 190 192 193 194 195 199 200 201 203 204 205 206\n",
      " 207 209 210 211 212 213 215 216 217 218 219 220 222 225 226 227 230 235\n",
      " 238 240 241 242 243 244 245 246 247 248 249 250 251 252 256 257 259 260\n",
      " 261 262 263 265 266 267 268 269 272 273 275 277 278 279 284 285 286 287\n",
      " 288 290 292 295 297 298 299 301 302 303 305 307 308 309 314 315 316] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  2   4   7   8   9  10  11  14  15  17  19  20  21  22  25  26  27  28\n",
      "  29  30  31  33  37  38  39  40  41  43  44  45  46  47  48  49  50  51\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  75  76  77  78  79  80  82  86  88  89  90  92  93  95  96\n",
      "  97 100 106 108 109 110 112 113 115 116 117 118 119 123 125 126 127 129\n",
      " 130 132 133 135 137 138 139 140 141 142 143 144 146 147 150 151 152 154\n",
      " 156 157 159 164 166 167 169 170 172 173 174 175 176 178 179 180 181 182\n",
      " 183 184 185 186 187 189 190 192 193 194 195 199 200 201 203 204 205 206\n",
      " 207 209 210 211 212 213 215 216 217 218 219 220 222 225 226 227 230 235\n",
      " 238 240 241 242 243 244 245 246 247 248 249 250 251 252 256 257 259 260\n",
      " 261 262 263 265 266 267 268 269 272 273 275 277 278 279 284 285 286 287\n",
      " 288 290 292 295 297 298 299 301 302 303 305 307 308 309 314 315 316] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [  2   4   7   8   9  10  11  14  15  17  19  20  21  22  25  26  27  28\n",
      "  29  30  31  33  37  38  39  40  41  43  44  45  46  47  48  49  50  51\n",
      "  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69\n",
      "  70  71  72  75  76  77  78  79  80  82  86  88  89  90  92  93  95  96\n",
      "  97 100 106 108 109 110 112 113 115 116 117 118 119 123 125 126 127 129\n",
      " 130 132 133 135 137 138 139 140 141 142 143 144 146 147 150 151 152 154\n",
      " 156 157 159 164 166 167 169 170 172 173 174 175 176 178 179 180 181 182\n",
      " 183 184 185 186 187 189 190 192 193 194 195 199 200 201 203 204 205 206\n",
      " 207 209 210 211 212 213 215 216 217 218 219 220 222 225 226 227 230 235\n",
      " 238 240 241 242 243 244 245 246 247 248 249 250 251 252 256 257 259 260\n",
      " 261 262 263 265 266 267 268 269 272 273 275 277 278 279 284 285 286 287\n",
      " 288 290 292 295 297 298 299 301 302 303 305 307 308 309 314 315 316] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy:  0.8931623931623932\n",
      "Training Accuracy:  0.9678800856531049\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  850\n",
      "Testing Accuracy:  0.905982905982906\n",
      "Training Accuracy:  0.9860813704496788\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  900\n",
      "Testing Accuracy:  0.9102564102564102\n",
      "Training Accuracy:  0.9775160599571735\n",
      "___________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def anova_selection(X, y, num_of_feat):\n",
    "    fs = SelectKBest(score_func=f_classif, k=num_of_feat)\n",
    "    fit = fs.fit(X, y)\n",
    "\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "    featureScores.columns = ['Best_columns', 'Score_anova']\n",
    "\n",
    "    lyst = featureScores.nlargest(num_of_feat, 'Score_anova')\n",
    "\n",
    "    anova_features = list(lyst['Best_columns'])\n",
    "    return anova_features\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"permission-based_malware_2.csv\")\n",
    "target = \"CLASS\"\n",
    "\n",
    "X = df.loc[:, df.columns != target]\n",
    "X = X.loc[:, X.columns != \"NAME\"]\n",
    "y = df[target]\n",
    "\n",
    "# Iterate over different numbers of features\n",
    "for i in range(50, len(X.columns), 50):\n",
    "    print(\"Number of columns: \", i)\n",
    "    anova_list = anova_selection(X, y, i)\n",
    "\n",
    "    X_ = df.loc[:, anova_list]\n",
    "    y_ = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=0)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=11, max_depth=26, random_state=0)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_test = rf.predict(X_test)\n",
    "    print(\"Testing Accuracy: \", accuracy_score(y_test, y_pred_test))\n",
    "    \n",
    "    y_pred_train = rf.predict(X_train)\n",
    "    print(\"Training Accuracy: \", accuracy_score(y_train, y_pred_train))\n",
    "    print(\"___________________________________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6367607d",
   "metadata": {},
   "source": [
    "## Chi-square Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "317681be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns:  50\n",
      "Testing Accuracy:  0.8846153846153846\n",
      "Training Accuracy:  0.9475374732334048\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  100\n",
      "Testing Accuracy:  0.8888888888888888\n",
      "Training Accuracy:  0.9678800856531049\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  150\n",
      "Testing Accuracy:  0.8888888888888888\n",
      "Training Accuracy:  0.9678800856531049\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  200\n",
      "Testing Accuracy:  0.8974358974358975\n",
      "Training Accuracy:  0.9775160599571735\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  250\n",
      "Testing Accuracy:  0.905982905982906\n",
      "Training Accuracy:  0.9764453961456103\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  300\n",
      "Testing Accuracy:  0.8974358974358975\n",
      "Training Accuracy:  0.9807280513918629\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  350\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.9775160599571735\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  400\n",
      "Testing Accuracy:  0.8974358974358975\n",
      "Training Accuracy:  0.9775160599571735\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  450\n",
      "Testing Accuracy:  0.9230769230769231\n",
      "Training Accuracy:  0.9753747323340471\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  500\n",
      "Testing Accuracy:  0.8931623931623932\n",
      "Training Accuracy:  0.9753747323340471\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  550\n",
      "Testing Accuracy:  0.8974358974358975\n",
      "Training Accuracy:  0.9710920770877944\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  600\n",
      "Testing Accuracy:  0.9102564102564102\n",
      "Training Accuracy:  0.9732334047109208\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  650\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.9753747323340471\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  700\n",
      "Testing Accuracy:  0.9145299145299145\n",
      "Training Accuracy:  0.9753747323340471\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  750\n",
      "Testing Accuracy:  0.9230769230769231\n",
      "Training Accuracy:  0.9785867237687366\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  800\n",
      "Testing Accuracy:  0.8931623931623932\n",
      "Training Accuracy:  0.9775160599571735\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  850\n",
      "Testing Accuracy:  0.9017094017094017\n",
      "Training Accuracy:  0.9764453961456103\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  900\n",
      "Testing Accuracy:  0.9145299145299145\n",
      "Training Accuracy:  0.9817987152034261\n",
      "___________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def chi2_selection(X, y, num_of_feat):\n",
    "    fs = SelectKBest(score_func=chi2, k=num_of_feat)\n",
    "    fit = fs.fit(X, y)\n",
    "\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "    featureScores.columns = ['Best_columns', 'Score_chi2']\n",
    "\n",
    "    lyst = featureScores.nlargest(num_of_feat, 'Score_chi2')\n",
    "\n",
    "    chi2_features = list(lyst['Best_columns'])\n",
    "    return chi2_features\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"permission-based_malware_2.csv\")\n",
    "target = \"CLASS\"\n",
    "\n",
    "X = df.loc[:, df.columns != target]\n",
    "X = X.loc[:, X.columns != \"NAME\"]\n",
    "y = df[target]\n",
    "\n",
    "# Iterate over different numbers of features\n",
    "for i in range(50, len(X.columns), 50):\n",
    "    print(\"Number of columns: \", i)\n",
    "    chi2_list = chi2_selection(X, y, i)\n",
    "\n",
    "    X_ = df.loc[:, chi2_list]\n",
    "    y_ = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=0)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators=11, max_depth=26, random_state=0)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_test = rf.predict(X_test)\n",
    "    print(\"Testing Accuracy: \", accuracy_score(y_test, y_pred_test))\n",
    "    \n",
    "    y_pred_train = rf.predict(X_train)\n",
    "    print(\"Training Accuracy: \", accuracy_score(y_train, y_pred_train))\n",
    "    print(\"___________________________________________________________________________________________\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
